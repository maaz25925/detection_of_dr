{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167fc3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Found 29840 images. Using 23 CPU cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀 Preprocessing Images:   0%|          | 0/29840 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# ADVANCED MULTI-CORE FUNDUS IMAGE PREPROCESSING PIPELINE\n",
    "# FOR DIABETIC RETINOPATHY DETECTION (MAX QUALITY + SPEED)\n",
    "# NOTE: This cell is adapted to run reliably inside Jupyter/VSCode notebooks\n",
    "# ===============================================================\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ===============================================================\n",
    "# 1. ADVANCED PREPROCESSING FUNCTIONS (Robust, notebook-friendly)\n",
    "# ===============================================================\n",
    "\n",
    "def crop_black(img, thresh=15):\n",
    "    \"\"\"Crop to the largest bright region (retina). Uses threshold + contours.\n",
    "\n",
    "    This is more robust than findNonZero on raw gray values which can fail\n",
    "    when images are not strictly zero-padded.\n",
    "    \"\"\"\n",
    "    if img is None:\n",
    "        return img\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # threshold to get the foreground (retina) - small thresh handles near-black backgrounds\n",
    "    _, bw = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return img\n",
    "    # pick largest contour (assumed retina)\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    # guard against empty crop\n",
    "    if w == 0 or h == 0:\n",
    "        return img\n",
    "    return img[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "def circular_mask(img, padding_factor=0.98):\n",
    "    \"\"\"Apply circular crop around the largest bright region's centroid.\n",
    "\n",
    "    Finds the largest contour and uses its centroid and minEnclosingCircle to create a mask.\n",
    "    Falls back to image center/radius if contour detection fails.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, bw = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        # robust center via moments\n",
    "        M = cv2.moments(c)\n",
    "        if M.get('m00', 0) != 0:\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "        else:\n",
    "            cx, cy = w // 2, h // 2\n",
    "        # use minEnclosingCircle to get an appropriate radius\n",
    "        (_, _), r = cv2.minEnclosingCircle(c)\n",
    "        radius = int(min(r * padding_factor, min(w, h) // 2))\n",
    "    else:\n",
    "        cx, cy = w // 2, h // 2\n",
    "        radius = min(w, h) // 2\n",
    "\n",
    "    mask = np.zeros((h, w), np.uint8)\n",
    "    cv2.circle(mask, (cx, cy), radius, 255, -1)\n",
    "    # apply mask\n",
    "    return cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "\n",
    "def clahe_enhance(img):\n",
    "    \"\"\"Improve contrast and vessel visibility using CLAHE on L channel.\"\"\"\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "\n",
    "def gamma_correction(img, gamma=1.2):\n",
    "    \"\"\"Brightness correction to normalize illumination.\"\"\"\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** invGamma * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(img, table)\n",
    "\n",
    "\n",
    "def preprocess_fundus(image_path, output_folder, input_folder, target_size=512):\n",
    "    \"\"\"Main preprocessing pipeline for a single image.\n",
    "\n",
    "    Returns True on success, False on failure.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Could not read image: {image_path}\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # Step 1: Crop black regions (robust)\n",
    "        img = crop_black(img)\n",
    "\n",
    "        # Step 2: Resize to target dimension\n",
    "        img = cv2.resize(img, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Step 3: Circular crop (centered on retina)\n",
    "        img = circular_mask(img)\n",
    "\n",
    "        # Step 4: CLAHE enhancement\n",
    "        img = clahe_enhance(img)\n",
    "\n",
    "        # Step 5: Gamma correction\n",
    "        img = gamma_correction(img, 1.2)\n",
    "\n",
    "        # Step 6: Gaussian blur subtraction (for vessel sharpening)\n",
    "        blur = cv2.GaussianBlur(img, (0, 0), 40)\n",
    "        img = cv2.addWeighted(img, 4, blur, -4, 128)\n",
    "\n",
    "        # Save processed image preserving folder structure\n",
    "        relative_path = os.path.relpath(image_path, input_folder)\n",
    "        save_path = os.path.join(output_folder, relative_path)\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        ok = cv2.imwrite(save_path, img)\n",
    "        if not ok:\n",
    "            print(f\"⚠️ Failed to write image: {save_path}\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {image_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 2. PARALLEL (notebook-friendly) PROCESSING FUNCTION\n",
    "# ===============================================================\n",
    "\n",
    "def process_all_images(input_folder, output_folder, num_workers=None, use_processes=False):\n",
    "    \"\"\"Process all images in dataset.\n",
    "\n",
    "    Defaults to a ThreadPoolExecutor which is safe in notebooks. Set use_processes=True\n",
    "    if you run this as a standalone script and prefer multiprocessing.\n",
    "    \"\"\"\n",
    "    if num_workers is None:\n",
    "        num_workers = max(1, cpu_count() - 1)\n",
    "\n",
    "    # Gather all image paths\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    print(f\"🧠 Found {len(image_paths)} images. Workers={num_workers}, use_processes={use_processes}\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    if use_processes:\n",
    "        # Multiprocessing path (best used when running as script, not in notebook)\n",
    "        from multiprocessing import Pool\n",
    "        with Pool(processes=num_workers) as pool:\n",
    "            list(tqdm(\n",
    "                pool.imap_unordered(\n",
    "                    partial(preprocess_fundus, output_folder=output_folder, input_folder=input_folder),\n",
    "                    image_paths\n",
    "                ),\n",
    "                total=len(image_paths),\n",
    "                desc=\"🚀 Preprocessing (processes)\"\n",
    "            ))\n",
    "\n",
    "    else:\n",
    "        # Threaded path (safe inside notebooks / interactive shells)\n",
    "        successes = 0\n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as exe:\n",
    "            futures = {exe.submit(preprocess_fundus, p, output_folder, input_folder): p for p in image_paths}\n",
    "            for f in tqdm(as_completed(futures), total=len(futures), desc=\"🚀 Preprocessing (threads)\"):\n",
    "                try:\n",
    "                    if f.result():\n",
    "                        successes += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Worker failed: {e}\")\n",
    "\n",
    "        print(f\"✅ Successfully processed {successes}/{len(image_paths)} images and saved to: {output_folder}\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 3. RUN PIPELINE – for your Kaggle DR dataset\n",
    "# NOTE: When running inside a notebook, call process_all_images(..., use_processes=False)\n",
    "# If running as a script (python m1.py), you can call with use_processes=True for true multiprocessing.\n",
    "# ===============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # TRAIN SET\n",
    "    input_folder_train = \"C:/Users/kondk/Downloads/archive (2)/split_dataset/train\"\n",
    "    output_folder_train = \"C:/Users/kondk/Downloads/archive (2)/split_dataset_processed/train\"\n",
    "    process_all_images(input_folder_train, output_folder_train, use_processes=True)\n",
    "\n",
    "    # VALIDATION SET\n",
    "    input_folder_val = \"C:/Users/kondk/Downloads/archive (2)/split_dataset/val\"\n",
    "    output_folder_val = \"C:/Users/kondk/Downloads/archive (2)/split_dataset_processed/val\"\n",
    "    process_all_images(input_folder_val, output_folder_val, use_processes=True)\n",
    "\n",
    "    # TEST SET\n",
    "    input_folder_test = \"C:/Users/kondk/Downloads/archive (2)/split_dataset/test\"\n",
    "    output_folder_test = \"C:/Users/kondk/Downloads/archive (2)/split_dataset_processed/test\"\n",
    "    process_all_images(input_folder_test, output_folder_test, use_processes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
